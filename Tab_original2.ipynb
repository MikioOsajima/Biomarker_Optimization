{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005dbd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Epoch 1/5\n",
      " [██████████████████████████████] 100.0%\n",
      "Loss: 144.8490\n",
      "\n",
      "Epoch 2/5\n",
      " [██████████████████████████████] 100.0%\n",
      "Loss: 141.2771\n",
      "\n",
      "Epoch 3/5\n",
      " [██████████████████████████████] 100.0%\n",
      "Loss: 141.0739\n",
      "\n",
      "Epoch 4/5\n",
      " [██████████████████████████████] 100.0%\n",
      "Loss: 140.6769\n",
      "\n",
      "Epoch 5/5\n",
      " [██████████████████████████████] 100.0%\n",
      "Loss: 139.4533\n",
      "Test Accuracy: 0.6503\n",
      "F1 Score     : 0.6693\n",
      "Precision    : 0.6357\n",
      "Recall       : 0.7066\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tab_transformer_pytorch import TabTransformer\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "# 1. データ読み込み（セミコロン区切り）\n",
    "data = pd.read_csv(\"cardio_train.csv\", sep=';') \n",
    "\n",
    "# 2. 特徴量の指定\n",
    "categorical_cols = ['gender', 'cholesterol', 'gluc', 'smoke', 'alco', 'active']\n",
    "continuous_cols = ['age', 'height', 'weight', 'ap_hi', 'ap_lo']\n",
    "target_col = 'cardio'                                                                       # 目的変数（分類するもの）の設定\n",
    "\n",
    "# 3. カテゴリ変数を数値化（LabelEncoder）\n",
    "for col in categorical_cols:\n",
    "    data[col] = LabelEncoder().fit_transform(data[col])                                     # 0, 1, 2, ... のように数値化する\n",
    "\n",
    "# 4. 連続値を正規化（平均0, 標準偏差1）\n",
    "scaler = StandardScaler()                                                                   # StandardScalerをインスタンス化\n",
    "data[continuous_cols] = scaler.fit_transform(data[continuous_cols])                         # 連続値を標準化する,これで学習が安定する\n",
    "\n",
    "# 5. 訓練/テストに分割\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# 6. PyTorch Dataset定義\n",
    "class CardioDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.categorical_data = dataframe[categorical_cols].values.astype(np.int64)\n",
    "        self.continuous_data = dataframe[continuous_cols].values.astype(np.float32)\n",
    "        self.labels = dataframe[target_col].values.astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.categorical_data[idx]),\n",
    "            torch.tensor(self.continuous_data[idx]),\n",
    "            torch.tensor(self.labels[idx])\n",
    "        )\n",
    "\n",
    "train_dataset = CardioDataset(train_data)\n",
    "test_dataset = CardioDataset(test_data)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256)\n",
    "\n",
    "# 7. TabTransformerモデル構築\n",
    "cont_mean_std = torch.tensor([[0.0, 1.0]] * len(continuous_cols))  # 標準化済みなので (mean=0, std=1)\n",
    "\n",
    "model = TabTransformer(\n",
    "    categories=(2, 3, 3, 2, 2, 2),  # 各カテゴリのユニーク数\n",
    "    num_continuous=5,\n",
    "    dim=32,\n",
    "    dim_out=1,\n",
    "    depth=4,\n",
    "    heads=4,\n",
    "    attn_dropout=0.1,\n",
    "    ff_dropout=0.1,\n",
    "    mlp_hidden_mults=(4, 2),\n",
    "    mlp_act=nn.ReLU(),\n",
    "    continuous_mean_std=cont_mean_std\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "model.categories_offset = model.categories_offset.to(device)\n",
    "\n",
    "\n",
    "# 8. 損失関数・最適化手法\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "# 9. 学習ループ\n",
    "def train_model(model, loader, epochs):\n",
    "    model.train()\n",
    "    total_batches = len(loader)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        for batch_idx, (x_categ, x_cont, y) in enumerate(loader):\n",
    "            x_categ = x_categ.to(device)  # ←追加\n",
    "            x_cont = x_cont.to(device)    # ←追加\n",
    "            y = y.to(device)              # ←追加\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x_categ, x_cont).squeeze(1)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # 進捗表示\n",
    "            progress = (batch_idx + 1) / total_batches * 100\n",
    "            bar_len = 30\n",
    "            filled_len = int(bar_len * progress / 100)\n",
    "            bar = '█' * filled_len + '-' * (bar_len - filled_len)\n",
    "            sys.stdout.write(f\"\\r [{bar}] {progress:5.1f}%\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        print(f\"\\nLoss: {total_loss:.4f}\")\n",
    "\n",
    "# 10. 評価関数\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "    with torch.no_grad():\n",
    "        for x_categ, x_cont, y in loader:\n",
    "            x_categ = x_categ.to(device)\n",
    "            x_cont = x_cont.to(device)\n",
    "            y = y.to(device)\n",
    "            out = model(x_categ, x_cont).squeeze(1)\n",
    "            prob = torch.sigmoid(out)\n",
    "            pred = (prob > 0.5).int()\n",
    "\n",
    "            preds.extend(pred.cpu().tolist())\n",
    "            trues.extend(y.int().cpu().tolist())\n",
    "\n",
    "    acc = accuracy_score(trues, preds)\n",
    "    f1 = f1_score(trues, preds)\n",
    "    precision = precision_score(trues, preds)\n",
    "    recall = recall_score(trues, preds)\n",
    "\n",
    "    print(f\"Test Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1 Score     : {f1:.4f}\")\n",
    "    print(f\"Precision    : {precision:.4f}\")\n",
    "    print(f\"Recall       : {recall:.4f}\")\n",
    "    return acc, f1, precision, recall\n",
    "\n",
    "# 11. 実行\n",
    "train_model(model, train_loader, epochs=5)\n",
    "evaluate_model(model, test_loader)\n",
    "\n",
    "\n",
    "def plot_confusion_and_roc(model, loader):\n",
    "    model.eval()\n",
    "    preds, trues, probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_categ, x_cont, y in loader:\n",
    "            x_categ = x_categ.to(device)  # ←追加\n",
    "            x_cont = x_cont.to(device)    # ←追加\n",
    "            y = y.to(device)              # ←追加\n",
    "            out = model(x_categ, x_cont).squeeze(1)\n",
    "            prob = torch.sigmoid(out)\n",
    "            pred = (prob > 0.5).int()\n",
    "\n",
    "            preds.extend(pred.tolist())\n",
    "            trues.extend(y.int().tolist())\n",
    "            probs.extend(prob.tolist())\n",
    "\n",
    "    # 混同行列\n",
    "    cm = confusion_matrix(trues, preds)\n",
    "    classes = ['Normal (0)', 'Cardio (1)']\n",
    "\n",
    "    # ROC\n",
    "    fpr, tpr, _ = roc_curve(trues, probs)\n",
    "    auc = roc_auc_score(trues, probs)\n",
    "\n",
    "    # 描画\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # 1. 混同行列\n",
    "    axs[0].imshow(cm, cmap='Blues')\n",
    "    axs[0].set_xticks(np.arange(len(classes)))\n",
    "    axs[0].set_yticks(np.arange(len(classes)))\n",
    "    axs[0].set_xticklabels(classes)\n",
    "    axs[0].set_yticklabels(classes)\n",
    "    axs[0].set_xlabel(\"Predicted Label\")\n",
    "    axs[0].set_ylabel(\"True Label\")\n",
    "    axs[0].set_title(\"Confusion Matrix\")\n",
    "\n",
    "    for i in range(len(classes)):\n",
    "        for j in range(len(classes)):\n",
    "            axs[0].text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "    # 2. ROC曲線\n",
    "    axs[1].plot(fpr, tpr, label=f\"AUC = {auc:.3f}\")\n",
    "    axs[1].plot([0, 1], [0, 1], 'k--')\n",
    "    axs[1].set_xlabel(\"False Positive Rate\")\n",
    "    axs[1].set_ylabel(\"True Positive Rate\")\n",
    "    axs[1].set_title(\"ROC Curve\")\n",
    "    axs[1].legend(loc=\"lower right\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 実行\n",
    "plot_confusion_and_roc(model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
