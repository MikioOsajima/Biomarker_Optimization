{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e08865d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Fold1 モデル読み込み: ./save_mask_models/best_model_epoch300_fold1_ValAcc0.732.pth ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold1 推論: 100%|██████████| 14000/14000 [17:06<00:00, 13.64件/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ fold1_results.csv saved\n",
      "\n",
      "=== Fold2 モデル読み込み: ./save_mask_models/best_model_epoch300_fold2_ValAcc0.739.pth ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold2 推論:  21%|██        | 2932/14000 [03:37<13:39, 13.51件/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 148\u001b[39m\n\u001b[32m    145\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ fold\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_results.csv saved\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 104\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    102\u001b[39m     x_alt[\u001b[32m0\u001b[39m, categorical_features.index(feat)] = \u001b[38;5;28mint\u001b[39m(val)\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m         conf_alt = torch.sigmoid(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_alt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_cont\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbool\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m).item()\n\u001b[32m    105\u001b[39m     exp_ent += entropy(conf_alt) * prob\n\u001b[32m    106\u001b[39m red = base_ent - exp_ent\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ドキュメント/program/Transformer_Study/fttransformer_pytorch/fttransformer_mask/models/ft_transformer.py:241\u001b[39m, in \u001b[36mFTTransformer.forward\u001b[39m\u001b[34m(self, x_categ, x_numer, mask_list, return_attn)\u001b[39m\n\u001b[32m    237\u001b[39m x = torch.cat((cls_tokens, x), dim = \u001b[32m1\u001b[39m)\n\u001b[32m    239\u001b[39m \u001b[38;5;66;03m# attend\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m x, attns = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_attn\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[38;5;66;03m# get cls token\u001b[39;00m\n\u001b[32m    245\u001b[39m x = x[:, \u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ドキュメント/program/Transformer_Study/fttransformer_pytorch/fttransformer_mask/models/ft_transformer.py:115\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, x, mask_list, return_attn)\u001b[39m\n\u001b[32m    112\u001b[39m x = \u001b[38;5;28mself\u001b[39m.expand_streams(x)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m attn, ff \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     x, post_softmax_attn = \u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m     post_softmax_attns.append(post_softmax_attn)\n\u001b[32m    118\u001b[39m     x = ff(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/hyper_connections/hyper_connections.py:305\u001b[39m, in \u001b[36mHyperConnections.forward\u001b[39m\u001b[34m(self, residuals, *branch_args, **branch_kwargs)\u001b[39m\n\u001b[32m    301\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m branch_input, add_residual_fn\n\u001b[32m    303\u001b[39m branch_output = \u001b[38;5;28mself\u001b[39m.branch(branch_input, *branch_args, **branch_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43madd_residual_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbranch_output\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/hyper_connections/hyper_connections.py:294\u001b[39m, in \u001b[36mHyperConnections.forward.<locals>.add_residual_fn\u001b[39m\u001b[34m(branch_out)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.add_branch_out_to_residual:\n\u001b[32m    292\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m branch_out\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m (branch_out, *rest), tree_spec = \u001b[43mtree_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbranch_out\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    296\u001b[39m branch_out = \u001b[38;5;28mself\u001b[39m.depth_connection(branch_out, residuals, **residual_kwargs)\n\u001b[32m    298\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten((branch_out, *rest), tree_spec)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/utils/_pytree.py:901\u001b[39m, in \u001b[36mtree_flatten\u001b[39m\u001b[34m(tree, is_leaf)\u001b[39m\n\u001b[32m    897\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Flattens a pytree into a list of values and a TreeSpec that can be used\u001b[39;00m\n\u001b[32m    898\u001b[39m \u001b[33;03mto reconstruct the pytree.\u001b[39;00m\n\u001b[32m    899\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    900\u001b[39m leaves: List[Any] = []\n\u001b[32m--> \u001b[39m\u001b[32m901\u001b[39m spec = \u001b[43m_tree_flatten_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleaves\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_leaf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_leaf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m leaves, spec\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/utils/_pytree.py:890\u001b[39m, in \u001b[36m_tree_flatten_helper\u001b[39m\u001b[34m(tree, leaves, is_leaf)\u001b[39m\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Recursively flatten the children\u001b[39;00m\n\u001b[32m    886\u001b[39m children_specs = [\n\u001b[32m    887\u001b[39m     _tree_flatten_helper(child, leaves, is_leaf=is_leaf) \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m child_pytrees\n\u001b[32m    888\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m890\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTreeSpec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchildren_specs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:3\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, type, context, children_specs)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from math import log\n",
    "from fttransformer_mask import FTTransformer\n",
    "\n",
    "# ============ 設定 ============\n",
    "DATA_PATH = \"cardio_train.csv\"\n",
    "TEST_RATIO = 0.2\n",
    "categorical_features = [\"gender\", \"cholesterol\", \"gluc\", \"smoke\", \"alco\", \"active\"]\n",
    "continuous_features = [\"age\", \"height\", \"weight\", \"ap_hi\", \"ap_lo\"]\n",
    "additional_features = [\"cholesterol\", \"gluc\", \"smoke\", \"alco\", \"active\"]\n",
    "MASK_BASE = [False, False] + [True] * 5 + [False] * 5\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "\n",
    "# エントロピー計算\n",
    "def entropy(p: float) -> float:\n",
    "    if p <= 0 or p >= 1:\n",
    "        return 0.0\n",
    "    return - (p * log(p) + (1 - p) * log(1 - p))\n",
    "\n",
    "# モデル保存パス\n",
    "fold_to_model_path = {\n",
    "    1: \"./save_mask_models/best_model_epoch300_fold1_ValAcc0.732.pth\",\n",
    "    2: \"./save_mask_models/best_model_epoch300_fold2_ValAcc0.739.pth\",\n",
    "    3: \"./save_mask_models/best_model_epoch300_fold3_ValAcc0.731.pth\",\n",
    "    4: \"./save_mask_models/best_model_epoch300_fold4_ValAcc0.737.pth\",\n",
    "    5: \"./save_mask_models/best_model_epoch300_fold5_ValAcc0.735.pth\",\n",
    "}\n",
    "\n",
    "def main():\n",
    "    data = pd.read_csv(DATA_PATH, sep=';')\n",
    "    ids = data[\"id\"].values\n",
    "    X = data.drop(columns=[\"cardio\"])\n",
    "    y = data[\"cardio\"]\n",
    "\n",
    "    X_trainval, X_test, y_trainval, y_test, id_trainval, id_test = \\\n",
    "        train_test_split(X, y, ids, test_size=TEST_RATIO, random_state=42, stratify=y)\n",
    "\n",
    "    # 前処理：エンコード＆スケール\n",
    "    encoders = {}\n",
    "    for col in categorical_features:\n",
    "        le = LabelEncoder()\n",
    "        X_trainval[col] = le.fit_transform(X_trainval[col])\n",
    "        X_test[col] = le.transform(X_test[col])\n",
    "        encoders[col] = le\n",
    "    scaler = StandardScaler()\n",
    "    X_trainval[continuous_features] = scaler.fit_transform(X_trainval[continuous_features])\n",
    "    X_test[continuous_features] = scaler.transform(X_test[continuous_features])\n",
    "\n",
    "    # 出現確率の再計算\n",
    "    feature_value_probs = {\n",
    "        feat: X_trainval[feat].value_counts(normalize=True).sort_index().to_dict()\n",
    "        for feat in additional_features\n",
    "    }\n",
    "\n",
    "    # 各foldごとに実行\n",
    "    for fold, model_path in fold_to_model_path.items():\n",
    "        print(f\"=== Fold{fold} モデル読み込み: {model_path} ===\")\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"❌ モデルが存在しません: {model_path}\")\n",
    "            continue\n",
    "\n",
    "        # モデルロード\n",
    "        model = FTTransformer(\n",
    "            categories=[X[cat].nunique() for cat in categorical_features],\n",
    "            num_continuous=len(continuous_features),\n",
    "            dim=64, depth=6, heads=8, ff_dropout=0.2, attn_dropout=0.2\n",
    "        ).to(DEVICE)\n",
    "        model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "        model.eval()\n",
    "\n",
    "        results = []\n",
    "        for i in tqdm(range(len(X_test)), desc=f\"Fold{fold} 推論\", unit=\"件\"):\n",
    "            sid = int(id_test[i])\n",
    "            label = int(y_test.iloc[i])\n",
    "            x_cat = torch.tensor([X_test.iloc[i][categorical_features].values], dtype=torch.long).to(DEVICE)\n",
    "            x_cont = torch.tensor([X_test.iloc[i][continuous_features].values.astype(np.float32)],\n",
    "                                dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "            # ベース推論＆エントロピー\n",
    "            with torch.no_grad():\n",
    "                base_conf = torch.sigmoid(model(x_cat, x_cont, torch.tensor([MASK_BASE],dtype=torch.bool).to(DEVICE))).item()\n",
    "            base_ent = entropy(base_conf)\n",
    "            base_pred = int(base_conf > 0.5)\n",
    "\n",
    "            # エントロピー削減量で特徴選択\n",
    "            best_red = -1.0\n",
    "            best_feat = None\n",
    "            for feat in additional_features:\n",
    "                mask = MASK_BASE.copy()\n",
    "                mask[2 + additional_features.index(feat)] = False\n",
    "                exp_ent = 0.0\n",
    "                for val, prob in feature_value_probs[feat].items():\n",
    "                    x_alt = x_cat.clone()\n",
    "                    x_alt[0, categorical_features.index(feat)] = int(val)\n",
    "                    with torch.no_grad():\n",
    "                        conf_alt = torch.sigmoid(model(x_alt, x_cont, torch.tensor([mask],dtype=torch.bool).to(DEVICE))).item()\n",
    "                    exp_ent += entropy(conf_alt) * prob\n",
    "                red = base_ent - exp_ent\n",
    "                if red > best_red:\n",
    "                    best_red = red\n",
    "                    best_feat = feat\n",
    "\n",
    "            # 改良後推論\n",
    "            final_mask = MASK_BASE.copy()\n",
    "            final_mask[2 + additional_features.index(best_feat)] = False\n",
    "            with torch.no_grad():\n",
    "                best_conf = torch.sigmoid(model(x_cat, x_cont, torch.tensor([final_mask],dtype=torch.bool).to(DEVICE))).item()\n",
    "            imp_pred = int(best_conf > 0.5)\n",
    "\n",
    "            results.append({\n",
    "                'id': sid,\n",
    "                'answer': label,\n",
    "                'base_pred': base_pred,\n",
    "                'improved_pred': imp_pred,\n",
    "                'chosen_feat': best_feat,\n",
    "            })\n",
    "\n",
    "        # 混同行列プロット（Blues）\n",
    "        y_true = [r['answer'] for r in results]\n",
    "        cm_base = confusion_matrix(y_true, [r['base_pred'] for r in results])\n",
    "        cm_imp  = confusion_matrix(y_true, [r['improved_pred'] for r in results])\n",
    "\n",
    "        disp = ConfusionMatrixDisplay(cm_base, display_labels=[0,1])\n",
    "        disp.plot(cmap='Blues')\n",
    "        plt.title(f\"Fold{fold} Base CM\")\n",
    "        plt.savefig(f\"fold{fold}_base_cm.png\")\n",
    "        plt.close()\n",
    "\n",
    "        disp = ConfusionMatrixDisplay(cm_imp, display_labels=[0,1])\n",
    "        disp.plot(cmap='Blues')\n",
    "        plt.title(f\"Fold{fold} Improved CM\")\n",
    "        plt.savefig(f\"fold{fold}_improved_cm.png\")\n",
    "        plt.close()\n",
    "\n",
    "        # CSV保存\n",
    "        pd.DataFrame(results).sort_values('id').to_csv(f\"fold{fold}_results.csv\", index=False)\n",
    "        print(f\"✅ fold{fold}_results.csv saved\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ec2e09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
